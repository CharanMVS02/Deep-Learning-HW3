{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb01937-6b17-43c4-a82c-dbf426fe6a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_squad_data(file_path):\n",
    "    # Open and load the JSON file into a dictionary\n",
    "    with open(file_path, 'rb') as f:\n",
    "        squad_data = json.load(f)\n",
    "\n",
    "    # Create lists to store contexts, questions, and answers\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    # Traverse through each section of data in the SQuAD file\n",
    "    for section in squad_data['data']:\n",
    "        for paragraph in section['paragraphs']:\n",
    "            context_text = paragraph['context']\n",
    "            for qa_pair in paragraph['qas']:\n",
    "                question_text = qa_pair['question']\n",
    "                # Determine if 'answers' or 'plausible_answers' should be accessed\n",
    "                answer_type = 'plausible_answers' if 'plausible_answers' in qa_pair else 'answers'\n",
    "                for answer in qa_pair[answer_type]:\n",
    "                    # Add the extracted data to their respective lists\n",
    "                    contexts.append(context_text)\n",
    "                    questions.append(question_text)\n",
    "                    answers.append(answer)\n",
    "    \n",
    "    # Return the lists with collected contexts, questions, and answers\n",
    "    return contexts, questions, answers\n",
    "\n",
    "# Use the function to load training and validation datasets\n",
    "train_contexts, train_questions, train_answers = load_squad_data('spoken_train-v1.1.json')\n",
    "val_contexts, val_questions, val_answers = load_squad_data('spoken_test-v1.1.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bcd5f8d-bc49-4103-86a6-c140866dc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_end_idx(answers, contexts):\n",
    "    # Iterate through each pair of answer and context\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        # Extract the expected answer text and its starting index\n",
    "        target_text = answer['text']\n",
    "        start_index = answer['answer_start']\n",
    "        # Calculate the tentative end index\n",
    "        end_index = start_index + len(target_text)\n",
    "\n",
    "        # Check if the answer aligns perfectly within the context\n",
    "        if context[start_index:end_index] == target_text:\n",
    "            # If it matches, assign the end index\n",
    "            answer['answer_end'] = end_index\n",
    "        else:\n",
    "            # Adjust for cases where the answer is slightly shifted\n",
    "            for offset in [1, 2]:\n",
    "                if context[start_index - offset:end_index - offset] == target_text:\n",
    "                    answer['answer_start'] = start_index - offset\n",
    "                    answer['answer_end'] = end_index - offset\n",
    "\n",
    "# Apply the function to both the training and validation answer lists\n",
    "set_end_idx(train_answers, train_contexts)\n",
    "set_end_idx(val_answers, val_contexts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a82d3a-552b-4d73-bb13-e1e880c525e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vmunaga/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "# Set up the tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the training and validation datasets\n",
    "train_encodings = tokenizer(\n",
    "    train_contexts,\n",
    "    train_questions,\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    val_contexts,\n",
    "    val_questions,\n",
    "    truncation=True,\n",
    "    padding=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73791292-101d-4285-a9ba-eafc017e8aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_token_positions(encodings, answers):\n",
    "    # Create lists to store the token indices for start and end positions\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for idx in range(len(answers)):\n",
    "        # Append start and end token positions using char_to_token method\n",
    "        start_positions.append(encodings.char_to_token(idx, answers[idx]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(idx, answers[idx]['answer_end']))\n",
    "\n",
    "        # Handle cases where the start position is None due to truncation\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "        # Adjust end position in case char_to_token returns None\n",
    "        offset = 1\n",
    "        while end_positions[-1] is None:\n",
    "            end_positions[-1] = encodings.char_to_token(idx, answers[idx]['answer_end'] - offset)\n",
    "            offset += 1\n",
    "\n",
    "    # Update the encodings object to include the new token-based start and end positions\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "# Use the function to process token positions for training and validation sets\n",
    "map_token_positions(train_encodings, train_answers)\n",
    "map_token_positions(val_encodings, val_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d646a420-5fb4-4c21-a3f4-c95200745694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class QADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve each encoding component as a tensor for a given index\n",
    "        return {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# Create datasets for training and validation data\n",
    "train_dataset = QADataset(train_encodings)\n",
    "val_dataset = QADataset(val_encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "517830f3-f2f4-430c-bcad-f574e3df89b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/vmunaga/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "# Load the DistilBERT model for question answering\n",
    "qa_model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e21798-e3e8-45c1-b33e-c88cf527f40f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Epoch 0: 100%|██████████| 2320/2320 [06:58<00:00,  5.54it/s, loss=3.49, lr=1.93e-6]\n",
      "Epoch 1: 100%|██████████| 2320/2320 [06:59<00:00,  5.52it/s, loss=1.64, lr=1.87e-6]\n",
      "Epoch 2: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=2.14, lr=1.8e-6]  \n",
      "Epoch 3: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=2.95, lr=1.73e-6] \n",
      "Epoch 4: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=2.6, lr=1.67e-6]  \n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Determine the device (GPU or CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "qa_model.to(device)\n",
    "qa_model.train()\n",
    "\n",
    "# Initialize Adam optimizer with learning rate\n",
    "optimizer = AdamW(qa_model.parameters(), lr=2e-6)\n",
    "\n",
    "# Set up DataLoader for the training dataset\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize scheduler to adjust learning rate over training\n",
    "total_training_steps = len(train_data_loader) * 30\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_training_steps\n",
    ")\n",
    "\n",
    "# Prepare the model, optimizer, and dataloader for multi-GPU/multi-CPU\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_data_loader, lr_scheduler = accelerator.prepare(qa_model, optimizer, train_data_loader, lr_scheduler)\n",
    "\n",
    "# Training loop for 5 epochs\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    progress_bar = tqdm(train_data_loader, leave=True)\n",
    "\n",
    "    # Iterate through batches\n",
    "    for batch in progress_bar:\n",
    "        # Zero out previous gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move batch data to the correct device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Perform a forward pass and calculate loss\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        start_positions=start_positions, end_positions=end_positions)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Perform backward pass and update parameters\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate schedule\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # Update the progress bar with loss and learning rate\n",
    "        progress_bar.set_description(f'Epoch {epoch}')\n",
    "        progress_bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d50a9d1-620f-4fdf-80d4-010a2db1f59d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/distilbert-custom/tokenizer_config.json',\n",
       " 'models/distilbert-custom/special_tokens_map.json',\n",
       " 'models/distilbert-custom/vocab.txt',\n",
       " 'models/distilbert-custom/added_tokens.json',\n",
       " 'models/distilbert-custom/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists('models'):\n",
    "   os.makedirs('models')\n",
    "model_path = 'models/distilbert-custom'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88627243-00e1-482b-9726-eaf7ab0aee99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages/transformers/modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "# Load the pre-trained model from the specified directory\n",
    "qa_model = DistilBertForQuestionAnswering.from_pretrained(\"models/HW3 Dataset for BERT Base Model\")\n",
    "\n",
    "# Move the model to the appropriate device (GPU or CPU)\n",
    "qa_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f2b6f4-8377-480f-99ef-4c891788784b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993/993 [01:12<00:00, 13.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize data loader for validation data\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Initialize list to store accuracy scores\n",
    "accuracy_scores = []\n",
    "\n",
    "# Set up the progress bar loop\n",
    "loop = tqdm(val_loader)\n",
    "\n",
    "# Initialize lists for storing predictions and references\n",
    "predicted_answers = []\n",
    "ground_truth_answers = []\n",
    "\n",
    "# Iterate through the validation dataset\n",
    "for batch in loop:\n",
    "    # No need for gradients since we're not training\n",
    "    with torch.no_grad():\n",
    "        # Extract the required tensors from the batch\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_true = batch['start_positions'].to(device)\n",
    "        end_true = batch['end_positions'].to(device)\n",
    "        \n",
    "        # Generate predictions from the model\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Get the start and end position predictions\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n",
    "        \n",
    "        # Calculate accuracy for both start and end positions\n",
    "        accuracy_scores.append(((start_pred == start_true).sum() / len(start_pred)).item())\n",
    "        accuracy_scores.append(((end_pred == end_true).sum() / len(end_pred)).item())\n",
    "        \n",
    "        # For each batch element, get the predicted and reference answers\n",
    "        for i in range(start_pred.shape[0]):\n",
    "            all_tokens = tokenizer.convert_ids_to_tokens(batch['input_ids'][i])\n",
    "            predicted_answer = ' '.join(all_tokens[start_pred[i]: end_pred[i] + 1])\n",
    "            reference_answer = ' '.join(all_tokens[start_true[i]: end_true[i] + 1])\n",
    "            \n",
    "            # Decode predicted answer tokens back to a string\n",
    "            predicted_answer_ids = tokenizer.convert_tokens_to_ids(predicted_answer.split())\n",
    "            decoded_answer = tokenizer.decode(predicted_answer_ids)\n",
    "            \n",
    "            # Append both the predicted and reference answers to their respective lists\n",
    "            predicted_answers.append(decoded_answer)\n",
    "            ground_truth_answers.append(reference_answer)\n",
    "\n",
    "# Compute the average accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "341ac5a4-96c0-44a0-9662-6ad0696e04f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "def process_answer(s):\n",
    "    \"\"\"Normalize text by converting to lowercase, removing punctuation, articles, and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def fix_whitespace(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def eliminate_punctuation(text):\n",
    "        punctuation_set = set(string.punctuation)\n",
    "        return ''.join(char for char in text if char not in punctuation_set)\n",
    "\n",
    "    def to_lowercase(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return fix_whitespace(remove_articles(eliminate_punctuation(to_lowercase(s))))\n",
    "\n",
    "\n",
    "def calculate_exact_match(prediction, ground_truth):\n",
    "    return (process_answer(prediction) == process_answer(ground_truth))\n",
    "\n",
    "\n",
    "def get_max_metric_for_truths(metric_fn, prediction, ground_truths):\n",
    "    scores = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores.append(score)\n",
    "    if len(scores) == 0:\n",
    "        return 0\n",
    "    return max(scores)\n",
    "\n",
    "\n",
    "def calculate_f1(prediction, ground_truth):\n",
    "    pred_tokens = process_answer(prediction).split()\n",
    "    gt_tokens = process_answer(ground_truth).split()\n",
    "    common_tokens = Counter(pred_tokens) & Counter(gt_tokens)\n",
    "    num_common = sum(common_tokens.values())\n",
    "    if num_common == 0:\n",
    "        return 0\n",
    "    precision = num_common / len(pred_tokens)\n",
    "    recall = num_common / len(gt_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def evaluate(gold_answers, predicted_answers):\n",
    "    total_f1 = total_exact_match = num_examples = 0\n",
    "\n",
    "    for ground_truths, prediction in zip(gold_answers, predicted_answers):\n",
    "        num_examples += 1\n",
    "        total_exact_match += get_max_metric_for_truths(calculate_exact_match, prediction, ground_truths)\n",
    "        total_f1 += get_max_metric_for_truths(calculate_f1, prediction, [ground_truths])\n",
    "\n",
    "    exact_match_percentage = 100.0 * total_exact_match / num_examples\n",
    "    f1_percentage = 100.0 * total_f1 / num_examples\n",
    "\n",
    "    return {'f1': f1_percentage}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "584b0a00-03d8-4afb-95ff-1de22f8af9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 47.93227405210848}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth_answers, predicted_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3163b7-f426-4890-9952-0605fd614aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
