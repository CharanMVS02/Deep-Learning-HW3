{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bd026b3-0831-4190-a27f-47fe4435bfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertTokenizerFast, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from evaluate import load\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57a4fce3-a827-4896-9f6b-ecc0c6d8f91f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_squad_data(filepath):\n",
    "    # Load the JSON file into a dictionary\n",
    "    with open(filepath, 'rb') as file:\n",
    "        squad_data = json.load(file)\n",
    "\n",
    "    # Prepare lists to store contexts, questions, and answers\n",
    "    contexts, questions, answers = [], [], []\n",
    "\n",
    "    # Iterate through each data entry in the SQuAD dataset\n",
    "    for group in squad_data['data']:\n",
    "        for paragraph in group['paragraphs']:\n",
    "            context_text = paragraph['context']\n",
    "            for qa_pair in paragraph['qas']:\n",
    "                question_text = qa_pair['question']\n",
    "                \n",
    "                # Determine if 'plausible_answers' or 'answers' should be used\n",
    "                answer_key = 'plausible_answers' if 'plausible_answers' in qa_pair else 'answers'\n",
    "                \n",
    "                # Append context, question, and each answer to the respective lists\n",
    "                for answer in qa_pair[answer_key]:\n",
    "                    contexts.append(context_text)\n",
    "                    questions.append(question_text)\n",
    "                    answers.append(answer)\n",
    "    \n",
    "    # Return the lists of contexts, questions, and answers\n",
    "    return contexts, questions, answers\n",
    "\n",
    "# Load the training and validation datasets\n",
    "train_contexts, train_questions, train_answers = load_squad_data('spoken_train-v1.1.json')\n",
    "val_contexts, val_questions, val_answers = load_squad_data('spoken_test-v1.1.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3371607-d5cd-4d96-8c8a-e41f21df5953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjust_end_index(answers, contexts):\n",
    "    # Iterate over each answer-context pair\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        # Get the expected answer text from the context\n",
    "        expected_text = answer['text']\n",
    "        # Capture the provided start index of the answer\n",
    "        start_idx = answer['answer_start']\n",
    "        # Calculate the initial end index\n",
    "        end_idx = start_idx + len(expected_text)\n",
    "\n",
    "        # Check if the context substring matches the answer exactly\n",
    "        if context[start_idx:end_idx] == expected_text:\n",
    "            # If it matches, set the end index directly\n",
    "            answer['answer_end'] = end_idx\n",
    "        else:\n",
    "            # Adjust in case the answer position is slightly off\n",
    "            for offset in [1, 2]:\n",
    "                if context[start_idx - offset:end_idx - offset] == expected_text:\n",
    "                    answer['answer_start'] = start_idx - offset\n",
    "                    answer['answer_end'] = end_idx - offset\n",
    "\n",
    "# Apply the function to both training and validation answer lists\n",
    "adjust_end_index(train_answers, train_contexts)\n",
    "adjust_end_index(val_answers, val_contexts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d18f2f8b-6ff7-4fbf-8967-21131c7d9a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "# Initialize the tokenizer using the pre-trained DistilBERT model\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize the training and validation sets with truncation and padding\n",
    "train_encodings = tokenizer(\n",
    "    train_contexts, train_questions, padding=True, truncation=True\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    val_contexts, val_questions, padding=True, truncation=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "153497a5-e226-413b-a6b1-509aa9e6cab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_token_positions(encodings, answers):\n",
    "    # Lists to store token start and end indices for each answer\n",
    "    start_positions, end_positions = [], []\n",
    "\n",
    "    # Iterate through each answer to determine token-based start and end indices\n",
    "    for idx in range(len(answers)):\n",
    "        # Use char_to_token method to get token positions of answer start and end\n",
    "        start_positions.append(encodings.char_to_token(idx, answers[idx]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(idx, answers[idx]['answer_end']))\n",
    "\n",
    "        # If the start position is None, it indicates the answer context was truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "\n",
    "        # Adjust end position if None by shifting until a valid token position is found\n",
    "        shift_offset = 1\n",
    "        while end_positions[-1] is None:\n",
    "            end_positions[-1] = encodings.char_to_token(idx, answers[idx]['answer_end'] - shift_offset)\n",
    "            shift_offset += 1\n",
    "\n",
    "    # Update the encodings object with calculated start and end token positions\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "# Apply the function to training and validation encodings\n",
    "map_token_positions(train_encodings, train_answers)\n",
    "map_token_positions(val_encodings, val_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2aa22dee-a404-490d-b2d5-e9b0e9894176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve each encoding entry and convert it to a tensor\n",
    "        return {key: torch.tensor(values[idx]) for key, values in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset based on input IDs\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# Create dataset objects for the training and validation sets\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eab9328b-d996-42b7-8eb8-23a15bf88a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "# Load the pre-trained DistilBERT model for question-answering tasks\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "641a3db0-622c-4574-8177-0cb2e12b4035",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2320/2320 [06:57<00:00,  5.55it/s, loss=2.87]\n",
      "Epoch 1: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=1.64]\n",
      "Epoch 2: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=1.69]\n",
      "Epoch 3: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=2.5]  \n",
      "Epoch 4: 100%|██████████| 2320/2320 [06:59<00:00,  5.53it/s, loss=1.08] \n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Determine the computing device: GPU if available, otherwise CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the model to the selected device\n",
    "model.to(device)\n",
    "\n",
    "# Enable training mode for the model\n",
    "model.train()\n",
    "\n",
    "# Set up AdamW optimizer with weight decay to mitigate overfitting\n",
    "optimizer = AdamW(model.parameters(), lr=2e-6)\n",
    "\n",
    "# Create data loader for training with a batch size of 16 and shuffling\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Training loop for 5 epochs\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    # Initialize the progress bar with tqdm\n",
    "    progress_bar = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Zero out any previously computed gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Retrieve batch tensors and move them to the appropriate device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Forward pass through the model to get outputs, including loss\n",
    "        outputs = model(input_ids, \n",
    "                        attention_mask=attention_mask, \n",
    "                        start_positions=start_positions, \n",
    "                        end_positions=end_positions)\n",
    "\n",
    "        # Extract the loss from the model's output\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backpropagate the loss to compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Apply optimizer step to update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar with current loss\n",
    "        progress_bar.set_description(f'Epoch {epoch}')\n",
    "        progress_bar.set_postfix(loss=loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22cc3084-a3b1-4c9d-914e-506f9400d149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a directory in your home directory\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "model_dir = os.path.join(home_dir, \"models\")\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save the model\n",
    "model_path = os.path.join(model_dir, \"distilbert-custom\")\n",
    "model.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7861d43-5f17-4121-b174-6622f7c84dda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBertForQuestionAnswering.from_pretrained(\"models/HW3 Dataset for BERT Base Model\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2dcaeb63-1090-45b0-9563-f6576cafce0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993/993 [01:12<00:00, 13.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Switch model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Set up data loader for the validation set with a batch size of 16\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Initialize list to store accuracy values\n",
    "accuracy_scores = []\n",
    "\n",
    "# Initialize progress bar loop\n",
    "progress_bar = tqdm(val_loader)\n",
    "\n",
    "# Lists to store predicted answers and reference answers\n",
    "predicted_answers = []\n",
    "reference_answers = []\n",
    "\n",
    "# Iterate through each batch in the validation set\n",
    "for batch in progress_bar:\n",
    "    # Disable gradient calculation for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Transfer batch data to the specified device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        true_start_positions = batch['start_positions'].to(device)\n",
    "        true_end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Extract start and end predictions using argmax\n",
    "        predicted_start = torch.argmax(output['start_logits'], dim=1)\n",
    "        predicted_end = torch.argmax(output['end_logits'], dim=1)\n",
    "\n",
    "        # Calculate accuracy for both start and end predictions, add to list\n",
    "        accuracy_scores.append((predicted_start == true_start_positions).sum().item() / len(predicted_start))\n",
    "        accuracy_scores.append((predicted_end == true_end_positions).sum().item() / len(predicted_end))\n",
    "\n",
    "        # Process predictions and references for each item in the batch\n",
    "        for idx in range(predicted_start.shape[0]):\n",
    "            tokens = tokenizer.convert_ids_to_tokens(batch['input_ids'][idx])\n",
    "            pred_answer = ' '.join(tokens[predicted_start[idx]:predicted_end[idx] + 1])\n",
    "            ref_answer = ' '.join(tokens[true_start_positions[idx]:true_end_positions[idx] + 1])\n",
    "            # Decode the predicted answer to text\n",
    "            predicted_answer_ids = tokenizer.convert_tokens_to_ids(pred_answer.split())\n",
    "            predicted_answer = tokenizer.decode(predicted_answer_ids)\n",
    "            predicted_answers.append(predicted_answer)\n",
    "            reference_answers.append(ref_answer)\n",
    "\n",
    "# Calculate the average accuracy over all batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd0808b0-2abc-4bdf-8920-f70f0635ba97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Convert text to lowercase, remove punctuation, articles, and extra whitespace.\"\"\"\n",
    "    \n",
    "    def remove_articles(input_text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', input_text)\n",
    "\n",
    "    def remove_punctuation(input_text):\n",
    "        punctuation_set = set(string.punctuation)\n",
    "        return ''.join(char for char in input_text if char not in punctuation_set)\n",
    "\n",
    "    def fix_whitespace(input_text):\n",
    "        return ' '.join(input_text.split())\n",
    "\n",
    "    def to_lowercase(input_text):\n",
    "        return input_text.lower()\n",
    "\n",
    "    # Apply all transformations to the text\n",
    "    return fix_whitespace(remove_articles(remove_punctuation(to_lowercase(text))))\n",
    "\n",
    "def compute_exact_match(prediction, reference):\n",
    "    return normalize_text(prediction) == normalize_text(reference)\n",
    "\n",
    "def compute_f1_score(prediction, reference):\n",
    "    prediction_tokens = normalize_text(prediction).split()\n",
    "    reference_tokens = normalize_text(reference).split()\n",
    "    common_tokens = Counter(prediction_tokens) & Counter(reference_tokens)\n",
    "    num_common = sum(common_tokens.values())\n",
    "    \n",
    "    if num_common == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    precision = num_common / len(prediction_tokens)\n",
    "    recall = num_common / len(reference_tokens)\n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "def best_score_over_references(metric_fn, prediction, references):\n",
    "    scores = [metric_fn(prediction, ref) for ref in references]\n",
    "    return max(scores) if scores else 0\n",
    "\n",
    "def evaluate_metrics(true_answers, model_predictions):\n",
    "    f1_total, exact_match_total, count = 0, 0, 0\n",
    "    \n",
    "    for ref_answers, pred_answer in zip(true_answers, model_predictions):\n",
    "        count += 1\n",
    "        exact_match_total += best_score_over_references(compute_exact_match, pred_answer, ref_answers)\n",
    "        f1_total += best_score_over_references(compute_f1_score, pred_answer, [ref_answers])\n",
    "    \n",
    "    exact_match_avg = 100.0 * exact_match_total / count\n",
    "    f1_avg = 100.0 * f1_total / count\n",
    "\n",
    "    return {'f1': f1_avg, 'exact_match': exact_match_avg}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f79f6fed-07b3-4827-8cc4-163adb36eae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 52.887876274954415, 'exact_match': 7.332283464566929}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the evaluate function with references and answers as inputs\n",
    "evaluate_metrics(reference_answers, predicted_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f6e97-ba04-4b95-984b-c6c2b2241906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
